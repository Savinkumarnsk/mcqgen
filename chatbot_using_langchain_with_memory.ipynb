{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Savinkumarnsk/mcqgen/blob/master/chatbot_using_langchain_with_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w7nSj69uwsvG"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain"
      ],
      "metadata": {
        "id": "D46wSB0sxRQ1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community"
      ],
      "metadata": {
        "id": "6x0fQWmUxVOr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install google-generativeai langchain\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBh-gQTCd4NrtSeO534KM8FznaMdDwXI94\"\n",
        "\n",
        "# Initialize the Gemini Pro model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", convert_system_message_to_human=True)\n"
      ],
      "metadata": {
        "id": "V3A87ok_FMV_",
        "outputId": "3bcc092d-ad6e-4204-a22e-f0e44dbcbe23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.68.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "4S8C0UITxzUx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"chatbot_with_langchain\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBh-gQTCd4NrtSeO534KM8FznaMdDwXI94\""
      ],
      "metadata": {
        "id": "-5iuio2VxbOd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "FihGZzLnx1i1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "U7XueMuWyKCt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"hi\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "csq2KSv7yScs",
        "outputId": "300b16fc-6e02-4a16-9604-fdc019232ce5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "DdS7zwgtyXNs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "_SUAIxLkylcl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser.invoke(model.invoke(\"hi\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "DS8er_IlyoD1",
        "outputId": "4a35ca32-cc20-4755-96fe-0be1a22e1c92"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "jA649nEF1Bda"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "KV4-RZkJ1MUX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  message = input(\"Write your query:\")\n",
        "  if message==\"bye\":\n",
        "    print(\"Good Bye have a great day!\")\n",
        "    break\n",
        "  else:\n",
        "    print(parser.invoke(model.invoke([HumanMessage(content=message)])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iksXylJ9yrae",
        "outputId": "848455c6-6496-4729-b344-d9fd3d03e45f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write your query:hi\n",
            "Hi there! How can I help you today?\n",
            "Write your query:can you explain chatbot\n",
            "Okay, let's break down what a chatbot is, how it works, and some common examples.\n",
            "\n",
            "**What is a Chatbot?**\n",
            "\n",
            "At its simplest, a chatbot is a computer program designed to simulate a conversation with a human user.  It's like a digital assistant that you can interact with through text or voice. Think of it as a digital representative that can answer questions, provide information, or perform tasks.\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "*   **Conversational Interface:** The primary way you interact with a chatbot is through a conversation, typically using natural language (the way humans normally talk).\n",
            "*   **Automated Responses:** Chatbots are programmed to respond to user input based on predefined rules or algorithms.  They analyze what you say or type and try to provide a relevant and helpful answer.\n",
            "*   **Task-Oriented or General Purpose:** Chatbots can be designed for specific tasks (like booking a flight) or for more general conversations (like answering FAQs).\n",
            "*   **Integration with Platforms:** Chatbots can be integrated into various platforms, including websites, messaging apps (like Facebook Messenger, WhatsApp, Slack), and voice assistants (like Alexa, Google Assistant).\n",
            "\n",
            "**How Chatbots Work (in a simplified way):**\n",
            "\n",
            "The core functionality of a chatbot revolves around understanding user input and generating appropriate responses. Here's a general overview of the process:\n",
            "\n",
            "1.  **User Input:**  You type or speak a message to the chatbot.\n",
            "\n",
            "2.  **Input Processing (Natural Language Processing - NLP):**\n",
            "    *   **Text Analysis:** The chatbot uses NLP techniques to analyze the user's text. This involves:\n",
            "        *   **Tokenization:** Breaking the text into individual words or phrases (tokens).\n",
            "        *   **Part-of-Speech Tagging:** Identifying the grammatical role of each word (noun, verb, adjective, etc.).\n",
            "        *   **Named Entity Recognition (NER):** Identifying important entities like names, dates, locations, organizations.\n",
            "        *   **Sentiment Analysis:** Determining the emotional tone of the user's message (positive, negative, neutral).\n",
            "    *   **Intent Recognition:**  The most crucial step. The chatbot tries to determine the *intent* or goal of the user's message.  What is the user trying to achieve? (e.g., \"book a flight,\" \"check the weather,\" \"get customer support\").  This is often done using machine learning models trained on large datasets of conversational data.\n",
            "    *   **Entity Extraction:**  Identifying specific pieces of information (entities) that are relevant to the user's intent.  For example, if the intent is \"book a flight,\" the entities might be the departure city, destination city, and travel dates.\n",
            "\n",
            "3.  **Response Generation:**\n",
            "    *   **Rule-Based Chatbots:**  If the chatbot is rule-based, it follows a predefined set of rules and logic to determine the appropriate response.  For example, \"If user asks about opening hours, respond with the opening hours stored in the database.\"\n",
            "    *   **AI-Powered Chatbots (using Machine Learning):**  More advanced chatbots use machine learning models (like neural networks) to generate responses. These models are trained on vast amounts of conversational data and can learn to generate more natural and contextually relevant responses.\n",
            "    *   **Retrieval-Based Models:**  These models select the best response from a predefined database of possible responses.\n",
            "    *   **Generative Models:** These models actually generate new responses from scratch, based on the user's input and the chatbot's training data.\n",
            "\n",
            "4.  **Output:** The chatbot presents its response to the user, either as text, voice, or even through graphical elements.\n",
            "\n",
            "**Types of Chatbots:**\n",
            "\n",
            "*   **Rule-Based Chatbots:**\n",
            "    *   **How they work:** Follow a predefined set of rules and keywords.\n",
            "    *   **Pros:** Easy to implement, predictable behavior.\n",
            "    *   **Cons:** Limited in scope, can't handle complex or unexpected queries, not very \"smart.\"\n",
            "    *   **Example:** A simple FAQ chatbot that responds to specific questions with predefined answers.\n",
            "*   **AI-Powered Chatbots (using Machine Learning):**\n",
            "    *   **How they work:** Use machine learning models (like neural networks) to understand user intent and generate responses.\n",
            "    *   **Pros:** More intelligent, can handle a wider range of queries, can learn and improve over time, more natural-sounding conversations.\n",
            "    *   **Cons:** More complex to develop and train, require large amounts of data, can be unpredictable at times.\n",
            "    *   **Examples:** Chatbots that can provide personalized recommendations, handle complex customer service inquiries, or engage in more open-ended conversations.\n",
            "*   **Hybrid Chatbots:** Combine rule-based and AI-powered approaches.  They might use rules for simple tasks and AI for more complex ones.\n",
            "\n",
            "**Examples of Chatbots:**\n",
            "\n",
            "*   **Customer Service Chatbots:**  Answer customer questions, provide support, and troubleshoot issues.  Often found on e-commerce websites.\n",
            "*   **E-commerce Chatbots:**  Help users find products, make purchases, and track orders.\n",
            "*   **Booking Chatbots:**  Allow users to book flights, hotels, or appointments.\n",
            "*   **Information Chatbots:** Provide information on a specific topic, such as weather, news, or sports scores.\n",
            "*   **Personal Assistant Chatbots:**  Help users manage their schedules, set reminders, and perform other tasks. (e.g., Siri, Google Assistant, Alexa)\n",
            "*   **Entertainment Chatbots:**  Engage users in games, quizzes, or other interactive experiences.\n",
            "\n",
            "**Benefits of Using Chatbots:**\n",
            "\n",
            "*   **24/7 Availability:**  Chatbots can provide support and information around the clock.\n",
            "*   **Cost Savings:**  Chatbots can automate tasks that would otherwise require human employees.\n",
            "*   **Improved Customer Service:**  Chatbots can provide quick and efficient responses to customer inquiries.\n",
            "*   **Increased Efficiency:**  Chatbots can automate repetitive tasks, freeing up human employees to focus on more complex work.\n",
            "*   **Personalized Experiences:**  Chatbots can provide personalized recommendations and experiences based on user data.\n",
            "*   **Lead Generation:** Chatbots can collect user information and qualify leads for sales teams.\n",
            "\n",
            "**Challenges of Using Chatbots:**\n",
            "\n",
            "*   **Limited Understanding:**  Chatbots can sometimes struggle to understand complex or ambiguous queries.\n",
            "*   **Lack of Empathy:**  Chatbots may not be able to provide the same level of empathy and understanding as a human.\n",
            "*   **Technical Issues:**  Chatbots can sometimes experience technical glitches or errors.\n",
            "*   **Security Concerns:**  Chatbots can be vulnerable to security attacks.\n",
            "*   **Development and Maintenance Costs:**  Developing and maintaining a chatbot can be expensive.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Chatbots are computer programs that simulate conversations with humans. They use natural language processing and machine learning to understand user intent and generate appropriate responses. They can be used for a variety of purposes, including customer service, e-commerce, and personal assistance. While they offer many benefits, they also have limitations and challenges.\n",
            "\n",
            "I hope this explanation is helpful! Let me know if you have any other questions.\n",
            "Write your query:end this section\n",
            "Okay, I will end this section. \n",
            "\n",
            "... (End of Section)\n",
            "Write your query:bye\n",
            "Good Bye have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import BaseChatMessageHistory"
      ],
      "metadata": {
        "id": "2CUWZj0H1HjU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory"
      ],
      "metadata": {
        "id": "ovwJtxBL2UUm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ],
      "metadata": {
        "id": "QTZIqm7J2V2M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage"
      ],
      "metadata": {
        "id": "hWOaeqby3Ttb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm cristinao\"),\n",
        "        AIMessage(content=\"Hello cristinao! How can I assist you today?\"),\n",
        "        HumanMessage(content=\"What's my name?\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "MNuPLxmd2Xtc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser.invoke(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nG_cTMDT3FRO",
        "outputId": "007bb3d9-e143-458c-e745-d3ed246e8e0f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is cristinao. You just told me. ðŸ˜Š'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store={}"
      ],
      "metadata": {
        "id": "EnmwiMRs3J4t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "NJQ3DRcp4A5V"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
      ],
      "metadata": {
        "id": "gNrB6mZX5KKK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory=RunnableWithMessageHistory(model,get_session_history)"
      ],
      "metadata": {
        "id": "CgNptPvs4WHF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"Hi! I'm savinkumar\")],config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z88Qe8yJ47zt",
        "outputId": "1eb7d6f8-eae2-45f1-9b70-d9e7482f4866"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Savinkumar! It's nice to meet you. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"what is my name?\")],config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PF-z4iF95VT1",
        "outputId": "e21f0e4a-dce5-461c-a70d-db97fb10bbdb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Savinkumar.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"secondtchat\"}}"
      ],
      "metadata": {
        "id": "-vXv3cMy5mGE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5S2LGmP58OX",
        "outputId": "49bc9d99-3b28-4d5c-f70d-51c672c9e0a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'session_id': 'secondtchat'}}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"what is my name?\")],config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "urT4ryhL52JP",
        "outputId": "e2f4ee51-4d2b-4191-9f9d-676c1a4780d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As a large language model, I have no way of knowing your name. You haven't told me!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
      ],
      "metadata": {
        "id": "ypjgSwc76ERZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9sePfBK6HSJ",
        "outputId": "f8ec9bb6-52a5-4efc-cbec-5f1fca5cbddc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'session_id': 'firstchat'}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJd1mJYh6Tmi",
        "outputId": "05bfa840-db17-4044-b6fd-238a094b145a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm savinkumar\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Savinkumar! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-35a2384d-c7b8-426d-95fd-b53645a98abf-0', usage_metadata={'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Savinkumar.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e3121204-6eda-4871-a45e-0a23154b2ffc-0', usage_metadata={'input_tokens': 33, 'output_tokens': 8, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}})]),\n",
              " 'secondtchat': InMemoryChatMessageHistory(messages=[HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I have no way of knowing your name. You haven't told me!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-b3469e96-4666-4588-a168-ec5acde6d334-0', usage_metadata={'input_tokens': 5, 'output_tokens': 23, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"what is my name?\")],config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MUQz4Tu25_pl",
        "outputId": "99a11374-c53c-4050-f9a1-4861edc3c668"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As far as I know, your name is Savinkumar. You told me that earlier. Is that incorrect?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ],
      "metadata": {
        "id": "DLDi0qEv6Jl9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability.\",),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "_foKOtDBCrTN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "iimbAou_DLV9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"messages\": [\"hi! I'm bob\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNpATGrFDctq",
        "outputId": "cc67c42f-7366-488c-8350-930b96d64aaa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hi Bob! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e8a419dc-04e7-4fb0-9dce-8799d682c654-0', usage_metadata={'input_tokens': 22, 'output_tokens': 19, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm bob\")]}).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2xqxlgmHDSOO",
        "outputId": "c270b0c8-55e0-4035-b43f-029c504bdcbc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Bob! It's nice to meet you. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"messages\": [HumanMessage(content=\"what is my name\")]}).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e-Ruhp0aDqld",
        "outputId": "44dfb17b-9af3-4129-8f76-91a76bf8fe9d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I do not have access to personal information like your name. As a large language model, I am designed to protect user privacy. Therefore, I cannot know your name.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory=RunnableWithMessageHistory(chain,get_session_history)"
      ],
      "metadata": {
        "id": "ECEVEifaD2Xk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"thirdchat\"}}"
      ],
      "metadata": {
        "id": "srFSbTmLEecx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Jim\"),\n",
        "     ],config=config\n",
        ")"
      ],
      "metadata": {
        "id": "DUOKZW96EIZl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jcPchc1bEVlM",
        "outputId": "f6af17b3-90eb-4a8b-f60e-a37bc36b110f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Jim! It's nice to meet you. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"hi what is my name\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLbAX0tGErVV",
        "outputId": "2bdc8e0f-5dfe-449a-8bee-b05dcf9e006b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your name is Jim. You told me that at the beginning of our conversation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"what is 2+2?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZQ2bd6RExK1",
        "outputId": "6b87134a-3299-4dca-96e0-1bbcbe377eec"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 2 = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"who is a indian cricket team caption?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjZZ4ODmE1YE",
        "outputId": "17bc8973-fba2-44db-8d99-311ead3c194e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current captain of the Indian cricket team (as of October 26, 2023) is **Rohit Sharma**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"what should i add in previous addition so that i will become 10?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkbBe3iQE6Ge",
        "outputId": "1e227f94-a7fb-47e4-ca34-cef03b69bf0b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous addition was 2 + 2 = 4.\n",
            "\n",
            "To get to 10 from 4, you need to add 6.\n",
            "\n",
            "So the answer is **6**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"what is my name?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Nc-1SRFBVY",
        "outputId": "4e415c9f-92cb-4668-9f1e-358f8b5ab2df"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your name is Jim.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-UASbCPFIg0",
        "outputId": "140d8faf-4f8f-4164-d175-23dd59f2e998"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm savinkumar\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Savinkumar! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-35a2384d-c7b8-426d-95fd-b53645a98abf-0', usage_metadata={'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Savinkumar.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e3121204-6eda-4871-a45e-0a23154b2ffc-0', usage_metadata={'input_tokens': 33, 'output_tokens': 8, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='As far as I know, your name is Savinkumar. You told me that earlier. Is that incorrect?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a619e1c1-ee14-4986-978b-ba7197acfb6f-0', usage_metadata={'input_tokens': 45, 'output_tokens': 24, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}})]),\n",
              " 'secondtchat': InMemoryChatMessageHistory(messages=[HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I have no way of knowing your name. You haven't told me!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-b3469e96-4666-4588-a168-ec5acde6d334-0', usage_metadata={'input_tokens': 5, 'output_tokens': 23, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})]),\n",
              " 'thirdchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Jim\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Jim! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-29655159-0997-4242-82c8-47396d65cb4d-0', usage_metadata={'input_tokens': 22, 'output_tokens': 19, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='hi what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Jim. You told me that at the beginning of our conversation!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bef1f63f-b018-4887-b2a9-090383830585-0', usage_metadata={'input_tokens': 45, 'output_tokens': 17, 'total_tokens': 62, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is 2+2?', additional_kwargs={}, response_metadata={}), AIMessage(content='2 + 2 = 4', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-30358fef-fc56-4311-9053-34dd15b3adfb-0', usage_metadata={'input_tokens': 68, 'output_tokens': 8, 'total_tokens': 76, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='who is a indian cricket team caption?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current captain of the Indian cricket team (as of October 26, 2023) is **Rohit Sharma**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-fddfb169-ea2f-4119-abeb-de62cda33c2b-0', usage_metadata={'input_tokens': 83, 'output_tokens': 28, 'total_tokens': 111, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what should i add in previous addition so that i will become 10?', additional_kwargs={}, response_metadata={}), AIMessage(content='The previous addition was 2 + 2 = 4.\\n\\nTo get to 10 from 4, you need to add 6.\\n\\nSo the answer is **6**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8954069a-49ae-41ef-a2b3-9d17e44a1211-0', usage_metadata={'input_tokens': 126, 'output_tokens': 40, 'total_tokens': 166, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Jim.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-cec3431e-50c4-4579-8116-29789498a662-0', usage_metadata={'input_tokens': 170, 'output_tokens': 6, 'total_tokens': 176, 'input_token_details': {'cache_read': 0}})])}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trimming the conversation"
      ],
      "metadata": {
        "id": "O2-MqelcXLhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, trim_messages"
      ],
      "metadata": {
        "id": "DQTMqEgC1xnr"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trimmer = trim_messages(\n",
        "    max_tokens=60,\n",
        "    strategy=\"last\",\n",
        "    token_counter=model,\n",
        "    include_system=True,\n",
        "    allow_partial=False,\n",
        "    start_on=\"human\",\n",
        ")"
      ],
      "metadata": {
        "id": "UvgZL0Zl1zPp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    HumanMessage(content=\"hi! I'm bob\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]"
      ],
      "metadata": {
        "id": "13lKIaG82QBM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_num_tokens_from_messages(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqGu2Zda2Ryy",
        "outputId": "1a94b9fa-de0f-441b-e85a-df06eebf4f7c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmer.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN9_6nINlHz2",
        "outputId": "1e7c5328-fefb-48af-f6f5-df47d7b37127"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_message = trimmer.invoke(messages)"
      ],
      "metadata": {
        "id": "QOyyzqgX0lNR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_num_tokens_from_messages(trimmed_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPzYA49N0ngI",
        "outputId": "51f61795-8f0f-4167-bd21-d3c6e7a30a4f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxRP1ei0211m",
        "outputId": "523b56ec-9716-41b4-bc57-ed2248db2268"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7f844b263100>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all questions to the best of your ability.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability.\",),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "o2kuCwBr2_77"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2lrmXS23ILH",
        "outputId": "dcf48054-2b1b-4fd8-c46f-309c0188354b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "212g4NcG3LRB",
        "outputId": "9426e29e-597d-4189-9a55-5dc1480e2e33"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_message+[HumanMessage(content=\"what's my name?\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPRZXXsy3Oag",
        "outputId": "b77b1ca6-2971-4e5e-979a-2b32ab3c96ea"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages+[HumanMessage(content=\"what's my name?\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUJ3iuOG3Yak",
        "outputId": "c3418ae2-40d6-4318-c5a4-86c9ce2b210f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
        "    | prompt\n",
        "    | model\n",
        ")\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG4Ux0YKlkTg",
        "outputId": "59b69b0c-7ece-40c4-88a9-6c05aa2dd930"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Bob!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4enzWFIXmRqX",
        "outputId": "0223cb84-e1a6-47ab-e652-cd56d4ac0a4a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You asked, \"what\\'s 2 + 2?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_memory = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "pLIK9Vj14PY0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"fifthchat\"}}"
      ],
      "metadata": {
        "id": "hQpDrVrZmWFW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_memory.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zomzpWPGm19R",
        "outputId": "6d9d5bbe-d936-4640-a531-3823dcc82636"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Bob! You told me at the beginning. ðŸ˜Š'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_memory.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BLOpblwum4Nm",
        "outputId": "1f47d2f7-440f-4609-ea92-9ab5e617e890"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I apologize, but I don't recall you asking me a math problem previously in our current conversation. Is there a specific math problem you'd like me to help you with now?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ytmtmdBJJm9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}